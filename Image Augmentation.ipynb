{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "emotions = [\"surprise\", \"fear\", \"disgust\", \"happy\", \"sadness\", \"angry\", \"neutral\", \"contempt\"]\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "for emotion in emotions:\n",
    "    images_data = glob.glob(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs\\\\%s\\\\*\" % emotion)\n",
    "    for image_path in images_data:\n",
    "        test_data.append(image_path)\n",
    "        test_labels.append(emotions.index(emotion))\n",
    "        \n",
    "        image_name = image_path.split(\"\\\\\")[-1]\n",
    "        after_flipping_image_name = \"flipping_\" + image_name\n",
    "        \n",
    "        pic = cv2.imread(image_path)\n",
    "        h_pic = cv2.flip(pic, 1)\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\flipping\\\\%s\" % (emotion, after_flipping_image_name), h_pic)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "emotions = [\"surprise\", \"fear\", \"disgust\", \"happy\", \"sadness\", \"angry\", \"neutral\", \"contempt\"]\n",
    "angle_list = [15, 30, 45, -15, -30, -45]\n",
    "\n",
    "def rotate(image, angle, scale=1.0):\n",
    "    height, width = image.shape[:2]\n",
    "    center = (width / 2, height / 2)\n",
    "\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    rotated = cv2.warpAffine(image, M, (height, width), borderValue=(255,255,255))\n",
    "    return rotated\n",
    "\n",
    "for emotion in emotions:\n",
    "    images_data = glob.glob(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs\\\\%s\\\\*\" % emotion)\n",
    "    for image_path in images_data:\n",
    "        image_name = image_path.split(\"\\\\\")[-1]\n",
    "        pic = cv2.imread(image_path)\n",
    "        for angle in angle_list:\n",
    "            after_Rotation_image_name = str(angle) + \"_rotation_\" + image_name\n",
    "            temp = rotate(pic, angle)\n",
    "            cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\rotation\\\\%s\\\\%s\" % (emotion,angle,after_Rotation_image_name), temp)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation without Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "from math import *\n",
    "emotions = [\"surprise\", \"fear\", \"disgust\", \"happy\", \"sadness\", \"angry\", \"neutral\", \"contempt\"]\n",
    "angle_list = [15, 30, 45, -15, -30, -45]\n",
    "\n",
    "def rotate(image, degree, scale=1.0):\n",
    "    height, width = image.shape[:2]\n",
    "    center = (width / 2, height / 2)\n",
    "\n",
    "    M = cv2.getRotationMatrix2D(center, degree, scale)\n",
    "\n",
    "    heightNew = int(width*fabs(sin(radians(degree)))+height*fabs(cos(radians(degree))))\n",
    "    widthNew = int(height*fabs(sin(radians(degree)))+width*fabs(cos(radians(degree))))\n",
    "\n",
    "    M[0, 2] += (widthNew-width)/2\n",
    "    M[1, 2] += (heightNew-height)/2\n",
    "\n",
    "    imgRotation=cv2.warpAffine(image, M, (widthNew, heightNew), borderValue=(255,255,255))\n",
    "\n",
    "    return imgRotation\n",
    "\n",
    "for emotion in emotions:\n",
    "    images_data = glob.glob(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs\\\\%s\\\\*\" % emotion)\n",
    "    for image_path in images_data:\n",
    "        image_name = image_path.split(\"\\\\\")[-1]\n",
    "        pic = cv2.imread(image_path)\n",
    "        for angle in angle_list:\n",
    "            after_Rotation_image_name = str(angle) + \"_rotation_without_crop_\" + image_name\n",
    "            temp = rotate(pic, angle)\n",
    "            cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\rotation_without_crop\\\\%s\\\\%s\" % (emotion,angle,after_Rotation_image_name), temp)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "emotions = [\"surprise\", \"fear\", \"disgust\", \"happy\", \"sadness\", \"angry\", \"neutral\", \"contempt\"]\n",
    "\n",
    "def translate(pic, x, y):\n",
    "    M = np.float32([[1, 0, x], [0, 1, y]])\n",
    "    shifted = cv2.warpAffine(pic, M, (width, height), borderValue=(255,255,255))\n",
    "    return shifted\n",
    "\n",
    "for emotion in emotions:\n",
    "    images_data = glob.glob(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs\\\\%s\\\\*\" % emotion)\n",
    "    for image_path in images_data:\n",
    "        image_name = image_path.split(\"\\\\\")[-1]\n",
    "        \n",
    "        pic = cv2.imread(image_path)\n",
    "        height, width = pic.shape[:2]\n",
    "        half_width = width/2\n",
    "        quarter_width = width/4\n",
    "        half_height = height/2\n",
    "        quarter_height = height/4 \n",
    "        \n",
    "        # shifting left -- quarter\n",
    "        after_shifting_image_name = \"left_quarter\" + \"_shifting_\" + image_name\n",
    "        shifted  = translate(pic, -quarter_width, 0)\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\shifting\\\\left_quarter\\\\%s\" % (emotion,after_shifting_image_name), shifted)\n",
    "\n",
    "        # shifting left -- half\n",
    "        after_shifting_image_name = \"left_half\" + \"_shifting_\" + image_name\n",
    "        shifted  = translate(pic, -half_width, 0)\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\shifting\\\\left_half\\\\%s\" % (emotion,after_shifting_image_name), shifted)\n",
    "\n",
    "        # shifting right -- quarter\n",
    "        after_shifting_image_name = \"right_quarter\" + \"_shifting_\" + image_name\n",
    "        shifted  = translate(pic, quarter_width, 0)\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\shifting\\\\right_quarter\\\\%s\" % (emotion,after_shifting_image_name), shifted)\n",
    "\n",
    "        # shifting right -- half\n",
    "        after_shifting_image_name = \"right_half\" + \"_shifting_\" + image_name\n",
    "        shifted  = translate(pic, half_width, 0)\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\shifting\\\\right_half\\\\%s\" % (emotion,after_shifting_image_name), shifted)\n",
    "\n",
    "        # shifting up -- quarter\n",
    "        after_shifting_image_name = \"up_quarter\" + \"_shifting_\" + image_name\n",
    "        shifted  = translate(pic, 0, -quarter_height)\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\shifting\\\\up_quarter\\\\%s\" % (emotion,after_shifting_image_name), shifted)\n",
    "\n",
    "        # shifting up -- half\n",
    "        after_shifting_image_name = \"up_half\" + \"_shifting_\" + image_name\n",
    "        shifted  = translate(pic, 0, -half_height)\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\shifting\\\\up_half\\\\%s\" % (emotion,after_shifting_image_name), shifted)\n",
    "\n",
    "        # shifting down -- quarter\n",
    "        after_shifting_image_name = \"down_quarter\" + \"_shifting_\" + image_name\n",
    "        shifted  = translate(pic, 0, quarter_height)\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\shifting\\\\down_quarter\\\\%s\" % (emotion,after_shifting_image_name), shifted)\n",
    "\n",
    "        # shifting down -- half\n",
    "        after_shifting_image_name = \"down_half\" + \"_shifting_\" + image_name\n",
    "        shifted  = translate(pic, 0, half_height)\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\shifting\\\\down_half\\\\%s\" % (emotion,after_shifting_image_name), shifted)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "emotions = [\"surprise\", \"fear\", \"disgust\", \"happy\", \"sadness\", \"angry\", \"neutral\", \"contempt\"]\n",
    "\n",
    "faceDet = cv2.CascadeClassifier(\"D:\\\\phd\\\\code\\\\Project1\\\\OpenCV_FaceCascade\\\\haarcascade_frontalface_default.xml\")\n",
    "faceDet_two = cv2.CascadeClassifier(\"D:\\\\phd\\\\code\\\\Project1\\\\OpenCV_FaceCascade\\\\haarcascade_frontalface_alt2.xml\")\n",
    "faceDet_three = cv2.CascadeClassifier(\"D:\\\\phd\\\\code\\\\Project1\\\\OpenCV_FaceCascade\\\\haarcascade_frontalface_alt.xml\")\n",
    "faceDet_four = cv2.CascadeClassifier(\"D:\\\\phd\\\\code\\\\Project1\\\\OpenCV_FaceCascade\\\\haarcascade_frontalface_alt_tree.xml\")\n",
    "\n",
    "def translate(pic, x, y):\n",
    "    M = np.float32([[1, 0, x], [0, 1, y]])\n",
    "    shifted = cv2.warpAffine(pic, M, (width, height), borderValue=(255,255,255))\n",
    "    return shifted\n",
    "\n",
    "def determine_face_size(frame, image_name):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    face = faceDet.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    face_two = faceDet_two.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    face_three = faceDet_three.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    face_four = faceDet_four.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    if len(face) == 1:\n",
    "        facefeatures = face\n",
    "    elif len(face_two) == 1:\n",
    "        facefeatures = face_two\n",
    "    elif len(face_three) == 1:\n",
    "        facefeatures = face_three\n",
    "    elif len(face_four) == 1:\n",
    "        facefeatures = face_four\n",
    "    else:\n",
    "        facefeatures = \"\"\n",
    "\n",
    "    for (x, y, w, h) in facefeatures:\n",
    "        print(\"face found in file: %s\" %image_name)\n",
    "        return x, x+w, y, y+h\n",
    "    \n",
    "for emotion in emotions:\n",
    "    images_data = glob.glob(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs\\\\%s\\\\*\" % emotion)\n",
    "    for image_path in images_data:\n",
    "        image_name = image_path.split(\"\\\\\")[-1]\n",
    "        \n",
    "        pic = cv2.imread(image_path)\n",
    "        height, width = pic.shape[:2]\n",
    "        face_x_start, face_x_end, face_y_start, face_y_end = determine_face_size(pic, image_name)\n",
    "        \n",
    "        face_height = face_y_end - face_y_start \n",
    "        face_width = face_x_end - face_x_start\n",
    "        \n",
    "        face_half_width = face_width/2\n",
    "        face_quarter_width = face_width/4\n",
    "        face_half_height = face_height/2\n",
    "        face_quarter_height = face_height/4 \n",
    "        \n",
    "        # shifting left -- quarter\n",
    "        after_shifting_image_name = \"left_quarter\" + \"_shifting_\" + image_name\n",
    "        shifted = translate(pic, -(face_x_start + face_quarter_width), 0)\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\new_shifting\\\\left_quarter\\\\%s\" % (emotion,after_shifting_image_name), shifted)\n",
    "\n",
    "        # shifting left -- half\n",
    "        after_shifting_image_name = \"left_half\" + \"_shifting_\" + image_name\n",
    "        shifted = translate(pic, -(face_x_start + face_half_width), 0)\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\new_shifting\\\\left_half\\\\%s\" % (emotion,after_shifting_image_name), shifted)\n",
    "\n",
    "        # shifting right -- quarter\n",
    "        after_shifting_image_name = \"right_quarter\" + \"_shifting_\" + image_name\n",
    "        shifted = translate(pic, width - face_x_end + face_quarter_width, 0)\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\new_shifting\\\\right_quarter\\\\%s\" % (emotion,after_shifting_image_name), shifted)\n",
    "\n",
    "        # shifting right -- half\n",
    "        after_shifting_image_name = \"right_half\" + \"_shifting_\" + image_name\n",
    "        shifted = translate(pic, width - face_x_end + face_half_width, 0)\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\new_shifting\\\\right_half\\\\%s\" % (emotion,after_shifting_image_name), shifted)\n",
    "\n",
    "        # shifting up -- quarter\n",
    "        after_shifting_image_name = \"up_quarter\" + \"_shifting_\" + image_name\n",
    "        shifted = translate(pic, 0, -(face_y_start + face_quarter_height))\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\new_shifting\\\\up_quarter\\\\%s\" % (emotion,after_shifting_image_name), shifted)\n",
    "\n",
    "        # shifting up -- half\n",
    "        after_shifting_image_name = \"up_half\" + \"_shifting_\" + image_name\n",
    "        shifted = translate(pic, 0, -(face_y_start + face_half_height))\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\new_shifting\\\\up_half\\\\%s\" % (emotion,after_shifting_image_name), shifted)\n",
    "\n",
    "        # shifting down -- quarter\n",
    "        after_shifting_image_name = \"down_quarter\" + \"_shifting_\" + image_name\n",
    "        shifted = translate(pic, 0, height - face_y_end + face_quarter_height)\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\new_shifting\\\\down_quarter\\\\%s\" % (emotion,after_shifting_image_name), shifted)\n",
    "\n",
    "        # shifting down -- half\n",
    "        after_shifting_image_name = \"down_half\" + \"_shifting_\" + image_name\n",
    "        shifted = translate(pic, 0, height - face_y_end + face_half_height)\n",
    "        cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\new_shifting\\\\down_half\\\\%s\" % (emotion,after_shifting_image_name), shifted)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additive white Gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "\n",
    "emotions = [\"surprise\", \"fear\", \"disgust\", \"happy\", \"sadness\", \"angry\", \"neutral\", \"contempt\"]\n",
    "noise_strengths_SD = [10, 20, 30, 40, 50, 60, 70]\n",
    "\n",
    "def convert_2d(r, noise_strength):\n",
    "\n",
    "    s = r + np.random.normal(0, noise_strength, r.shape)\n",
    "    if np.min(s) >= 0 and np.max(s) <= 255:\n",
    "        return s\n",
    "\n",
    "    s = s - np.full(s.shape, np.min(s))\n",
    "    s = s * 255 / np.max(s)\n",
    "    s = s.astype(np.uint8)\n",
    "    return s\n",
    "\n",
    "\n",
    "def convert_3d(r, noise_strength):\n",
    "    s_dsplit = []\n",
    "    for d in range(r.shape[2]):\n",
    "        rr = r[:, :, d]\n",
    "        ss = convert_2d(rr, noise_strength)\n",
    "        s_dsplit.append(ss)\n",
    "    s = np.dstack(s_dsplit)\n",
    "    return s\n",
    "\n",
    "for emotion in emotions:\n",
    "    images_data = glob.glob(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs\\\\%s\\\\*\" % emotion)\n",
    "    for image_path in images_data:\n",
    "        image_name = image_path.split(\"\\\\\")[-1]\n",
    "        pic = PIL.Image.open(image_path)\n",
    "        pic = pic.convert('RGB')\n",
    "        pic_mat = scipy.misc.fromimage(pic)\n",
    "        \n",
    "        for noise_strength in noise_strengths_SD:\n",
    "            after_add_white_gasussian_noise_image_name = str(noise_strength) + \"_noise_strength_\" + image_name\n",
    "            pic_converted_mat = convert_3d(pic_mat, noise_strength)\n",
    "            pic_converted = PIL.Image.fromarray(pic_converted_mat)\n",
    "            pic_converted.save(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\gaussian_noise\\\\%s\\\\%s\" % (emotion,noise_strength,after_add_white_gasussian_noise_image_name))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian_blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFilter, Image\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "emotions = [\"surprise\", \"fear\", \"disgust\", \"happy\", \"sadness\", \"angry\", \"neutral\", \"contempt\"]\n",
    "blur_level_dic = {\"L_1\": 1, \"L_2\": 3, \"L_3\": 10}\n",
    "\n",
    "def add_gaussian_blur(image, radi):   \n",
    "    out = image.filter(ImageFilter.GaussianBlur(radius=radi))\n",
    "    return out\n",
    "\n",
    "for emotion in emotions:\n",
    "    images_data = glob.glob(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs\\\\%s\\\\*\" % emotion)\n",
    "    for image_path in images_data:\n",
    "        image_name = image_path.split(\"\\\\\")[-1]\n",
    "        pic = Image.open(image_path)\n",
    "        for blur_level in blur_level_dic:\n",
    "            after_add_gaussian_blur_image_name = blur_level + \"_gaussian_blur_\" + image_name\n",
    "            temp = add_gaussian_blur(pic, blur_level_dic[blur_level])\n",
    "            temp.save(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\gaussian_blur\\\\%s\\\\%s\" % (emotion,blur_level,after_add_gaussian_blur_image_name))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illumination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "emotions = [\"surprise\", \"fear\", \"disgust\", \"happy\", \"sadness\", \"angry\", \"neutral\", \"contempt\"]\n",
    "illumination_level_dic = {\"L_1\": 0.33, \"L_2\": 0.5, \"L_3\": 2, \"L_4\": 3}\n",
    "\n",
    "def adjust_gamma(image, gamma):\n",
    "    print(\"%%%%%%%%%%%\")\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([\n",
    "      ((i / 255.0) ** invGamma) * 255\n",
    "      for i in np.arange(0, 256)])\n",
    "    return cv2.LUT(image.astype(np.uint8), table.astype(np.uint8))\n",
    "\n",
    "for emotion in emotions:\n",
    "    images_data = glob.glob(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs\\\\%s\\\\*\" % emotion)\n",
    "    for image_path in images_data:\n",
    "        image_name = image_path.split(\"\\\\\")[-1]\n",
    "        pic = cv2.imread(image_path)\n",
    "        for illumination_level in illumination_level_dic:\n",
    "            after_add_illumination_image_name = illumination_level + \"_illumination_\" + image_name\n",
    "            temp = adjust_gamma(pic, illumination_level_dic[illumination_level])\n",
    "            cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\new_illumination\\\\%s\\\\%s\" % (emotion,illumination_level,after_add_illumination_image_name), temp)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "emotions = [\"surprise\", \"fear\", \"disgust\", \"happy\", \"sadness\", \"angry\", \"neutral\", \"contempt\"]\n",
    "brightness_percent_list = [25, 50, 75, -25, -50, -75]\n",
    "\n",
    "def adjust_brightness(img, percent):\n",
    "    print(\"###################\")\n",
    "    new_image = np.zeros(img.shape, img.dtype)\n",
    "    alpha = 1.0\n",
    "    per = percent / 100.0 * 255\n",
    "    if percent > 0:\n",
    "        for y in range(img.shape[0]):\n",
    "            for x in range(img.shape[1]):\n",
    "                for c in range(img.shape[2]):\n",
    "                    new_image[y, x, c] = np.clip(alpha * img[y, x, c] + per, 0, 255)\n",
    "\n",
    "    else:\n",
    "        for y in range(img.shape[0]):\n",
    "            for x in range(img.shape[1]):\n",
    "                for c in range(img.shape[2]):\n",
    "                    new_image[y, x, c] = np.clip(alpha * img[y, x, c] + per, 0, 255)\n",
    "\n",
    "    return new_image\n",
    "\n",
    "for emotion in emotions:\n",
    "    images_data = glob.glob(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs\\\\%s\\\\*\" % emotion)\n",
    "    for image_path in images_data:\n",
    "        image_name = image_path.split(\"\\\\\")[-1]\n",
    "        pic = cv2.imread(image_path)\n",
    "        for percent in brightness_percent_list:\n",
    "            after_brightness_image_name = str(percent) + \"%_brightness_\" + image_name\n",
    "            temp = adjust_brightness(pic, percent)\n",
    "            cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\brightness\\\\%s\\\\%s\" % (emotion,percent,after_brightness_image_name), temp)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "emotions = [\"surprise\", \"fear\", \"disgust\", \"happy\", \"sadness\", \"angry\", \"neutral\", \"contempt\"]\n",
    "color_jitter_level_dic = {\"L_1\": 1, \"L_2\": 5, \"L_3\": 10}\n",
    "\n",
    "def add_color_jitter(image, sh):\n",
    "    R = image[:,:,0]\n",
    "    G = image[:,:,1]\n",
    "    B = image[:,:,2]\n",
    "    RGBshifted = np.dstack((np.roll(R, sh, axis=0), np.roll(G, sh, axis=1), np.roll(B, -sh, axis=0)))\n",
    "    return RGBshifted\n",
    "\n",
    "for emotion in emotions:\n",
    "    images_data = glob.glob(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs\\\\%s\\\\*\" % emotion)\n",
    "    for image_path in images_data:\n",
    "        image_name = image_path.split(\"\\\\\")[-1]\n",
    "        pic = cv2.imread(image_path)\n",
    "        for color_jitter_level in color_jitter_level_dic:\n",
    "            after_add_color_jitter_image_name = color_jitter_level + \"_color_jitter_\" + image_name\n",
    "            temp = add_color_jitter(pic, color_jitter_level_dic[color_jitter_level])\n",
    "            cv2.imwrite(\"D:\\\\phd\\\\code\\\\Project1\\\\Study1_database\\\\test_data_for_APIs_augmentation\\\\%s\\\\color_jitter\\\\%s\\\\%s\" % (emotion,color_jitter_level,after_add_color_jitter_image_name), temp)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

